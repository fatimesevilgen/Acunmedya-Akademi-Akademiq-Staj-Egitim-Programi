{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f753cd5a",
   "metadata": {},
   "source": [
    "## Vectorize İşlemi Nedir?\n",
    "\n",
    "Metin verilerini makine öğrenmesi modellerine besleyebilmek için sayısal forma dönüştürme işlemine **vektörizasyon** denir. Ham metin (string) formatındaki veriler, modeller tarafından anlaşılamaz; bu nedenle her kelime veya n-gram özellik olarak sayısal bir değere sahip bir vektöre dönüştürülür.\n",
    "\n",
    "---\n",
    "\n",
    "## TF-IDF Nedir?\n",
    "\n",
    "**TF-IDF (Term Frequency-Inverse Document Frequency)**, kelimelerin belgeler içindeki önemini ölçen yaygın bir vektörizasyon yöntemidir. İki temel bileşeni vardır:\n",
    "\n",
    "- **TF (Term Frequency)**: Bir belgedeki bir kelimenin ne sıklıkla göründüğünü ölçer.\n",
    "- **IDF (Inverse Document Frequency)**: Kelimenin tüm belgeler arasında ne kadar nadir olduğunu ölçer.\n",
    "\n",
    "TF-IDF skoru, bir kelimenin belgede sık geçtiği ve aynı zamanda diğer belgelerde nadiren kullanıldığı durumları öne çıkarır.\n",
    "\n",
    "---\n",
    "\n",
    "## Formüller\n",
    "\n",
    "- **Term Frequency (TF)**\n",
    "\n",
    "  \\[\n",
    "    TF(t, d) = \\frac{f_{t,d}}{\\sum_{k} f_{k,d}}\n",
    "  \\]\n",
    "\n",
    "  - *f<sub>t,d</sub>*: Belge *d* içindeki *t* teriminin frekansı.\n",
    "  - Pay kısım tüm terimlerin toplam frekansı.\n",
    "\n",
    "- **Inverse Document Frequency (IDF)**\n",
    "\n",
    "  \\[\n",
    "    IDF(t, D) = \\log\\left(\\frac{N}{1 + |\\{d \\in D: t \\in d\\}|}\\right)\n",
    "  \\]\n",
    "\n",
    "  - *N*: Toplam belge sayısı.\n",
    "  - *|\\{d \\in D: t \\in d\\}|*: *t* terimini içeren belge sayısı.\n",
    "\n",
    "- **TF-IDF**\n",
    "\n",
    "  \\[\n",
    "    TF\\text{-}IDF(t, d, D) = TF(t,d) \\times IDF(t,D)\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "## Örnek Kullanım\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Örnek metin koleksiyonu (corpus)\n",
    "corpus = [\n",
    "    'Bu bir örnek cümle',\n",
    "    'TF-IDF vektörleştirme işlemi',\n",
    "    'Makine öğrenmesi için metin ön işleme'\n",
    "]\n",
    "\n",
    "# Vectorizer nesnesi oluşturma\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit ve transform işlemi\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Özellik isimleri (vokabüloryum)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print('Özellikler:', feature_names)\n",
    "\n",
    "# TF-IDF matrisini dizi olarak gösterme\n",
    "dense_matrix = X.toarray()\n",
    "print('TF-IDF Matrisi:\n",
    "', dense_matrix)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08809675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Örnek metin koleksiyonu (corpus)\n",
    "corpus = [\n",
    "    'Bu bir örnek cümle',\n",
    "    'TF-IDF vektörleştirme işlemi',\n",
    "    'Makine öğrenmesi için metin ön işleme'\n",
    "]\n",
    "\n",
    "# Vectorizer nesnesi oluşturma\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit ve transform işlemi\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Özellik isimleri (vokabüloryum)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print('Özellikler:', feature_names)\n",
    "\n",
    "# TF-IDF matrisini dizi olarak gösterme\n",
    "dense_matrix = X.toarray()\n",
    "print('TF-IDF Matrisi:\\n', dense_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d8626bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\nth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\n( see a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\nho ho ho , we ' re arou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\nthis deal is to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\nth...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\n( see a...   \n",
       "2        3624   ham  Subject: neon retreat\\nho ho ho , we ' re arou...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\nthis deal is to ...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('spam_ham_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b84a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\nth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\n( see a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: neon retreat\\nho ho ho , we ' re arou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : indian springs\\nthis deal is to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label_num\n",
       "0  Subject: enron methanol ; meter # : 988291\\nth...          0\n",
       "1  Subject: hpl nom for january 9 , 2001\\n( see a...          0\n",
       "2  Subject: neon retreat\\nho ho ho , we ' re arou...          0\n",
       "3  Subject: photoshop , windows , office . cheap ...          1\n",
       "4  Subject: re : indian springs\\nthis deal is to ...          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"text\", \"label_num\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a66d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def clean_text(text:str):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    words = text.split()\n",
    "    words = [word for word in words if not word.isdigit()]\n",
    "    words = [ps.stem(word) for word in words if word not in stopwords.words(\"english\")]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfcd85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\nth...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject enron methanol meter follow note gave ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\n( see a...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject hpl nom januari see attach file hplnol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: neon retreat\\nho ho ho , we ' re arou...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject neon retreat ho ho ho around wonder ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject photoshop window offic cheap main tren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : indian springs\\nthis deal is to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject indian spring deal book teco pvr reven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label_num  \\\n",
       "0  Subject: enron methanol ; meter # : 988291\\nth...          0   \n",
       "1  Subject: hpl nom for january 9 , 2001\\n( see a...          0   \n",
       "2  Subject: neon retreat\\nho ho ho , we ' re arou...          0   \n",
       "3  Subject: photoshop , windows , office . cheap ...          1   \n",
       "4  Subject: re : indian springs\\nthis deal is to ...          0   \n",
       "\n",
       "                                          clean_text  \n",
       "0  subject enron methanol meter follow note gave ...  \n",
       "1  subject hpl nom januari see attach file hplnol...  \n",
       "2  subject neon retreat ho ho ho around wonder ti...  \n",
       "3  subject photoshop window offic cheap main tren...  \n",
       "4  subject indian spring deal book teco pvr reven...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5df75162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f395d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best parameters found:  {'tfidf__max_df': 0.75, 'tfidf__max_features': None, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 3)}\n",
      "Best cross-validation score:  0.9666354146586521\n",
      "Test set score:  0.9594202898550724\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X = df[\"clean_text\"]\n",
    "y = df[\"label_num\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"model\", MultinomialNB())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    # 1-gram, 2-gram ve 3-gram deniyoruz\n",
    "    'tfidf__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    # En az 2, 5 veya 10 dokümanda geçen kelimeler\n",
    "    'tfidf__min_df': [2, 5, 10],\n",
    "    # En çok dokümanların %75, %85 veya %95’inde geçen kelimeleri at\n",
    "    'tfidf__max_df': [0.75, 0.85, 0.95],\n",
    "    # En fazla 2k, 5k, 10k veya bütün kelimeler\n",
    "    'tfidf__max_features': [2000, 5000, 10000, None],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", grid.best_params_)\n",
    "print(\"Best cross-validation score: \", grid.best_score_)\n",
    "print(\"Test set score: \", grid.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef200805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
